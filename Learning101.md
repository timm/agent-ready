The learning mechanism in Actory is a tool that biases machine/transition selection (so it will all be in sub-classes of Stagger).

Biases are learned from watching an oracle score the simulation outputs.
  * Bias<sub>0</sub> is fully random (i.e. the current Stagger)
  * Bias<sub>i</sub> influences what transitions fire
  * Bias<sub>i+1</sub> learned from experience with the running model.

For N simulations:
  * reset
  * run
  * score the output

Generate a table:
  * One column for each transition.
  * One row for each of the N simulations

For each row:
  * Count the number of times each transition fires.
  * Divide those counts by the total number of transitions fired in that row.
  * Add one more column for a _score_ generated by some _oracle_.

Classify the rows
  * Sort the rows
  * Separate them out into B% _best_ and (100-B)% _rest_.

Re-bias
  * Increase the bias on transition<sub>x</sub> if it appears _more_ frequently in best than _rest_.
  * Normalize all the new biases by (bias<sub>i</sub>) /(∑ bias<sub>i</sub>)
    * So all biases are between zero and one.

Singleton re-normalization
  * Select new biases
  * Sort the transitions in their normalized biased order.
  * Pick _u_ at random (zero to one)
  * Perhaps, bias _u_ to favor the most likely transitions.
  * Starting from transition 2
  * Select transition  _i_ if _u_ is  greater than bucket _u+1_.
```
function pick(cdf,n,  bias,u,i) {
    u = bias ? rand()^bias : rand()
    for(i=n-1;i>=1;i--) 
        if (u > cdf[i] ) 
            return i+1
    return n
}
```
  * Note: if w < 1, favors lower biased values less and less.

Repeat for multiple _rounds_ (N runs, re-biasing, repeat).

Visualize the results
  * See Figure 5 of [Keys2](http://agent-ready.googlecode.com/svn/trunk/share/pdf/keys2.pdf)
  * Median = 50th percentile
  * Spread = 75th percentile
  * Success if:
    * Better medians (better performance)
    * Smaller spreads (more certainty)

# One Million Questions #
Have you made enough decision / domain decisions explicit?
  * If important options aren't in the transitions, then this learner won't work.
Have you made too many decision / domain decisions explicit?
  * If you code too many transitions, then the learning will fail.
At what level do you learn?
  * All factories/machines/transitions in one big table?
    * Default: yes
  * Manually separate by factory?
  * Manually separate by machine?
  * Automatically separate by clustering?
    * For a fast incremental clusterer, see [Gupta'04](http://ourmine.googlecode.com/svn/trunk/share/pdf/gupta04.pdf)'s GENIC algorithm
Is the model running too slow?
  * If the final model takes too long to run..
  * .. need to cluster the log of prior behavior and only try new behaviors in zones of high variability
    * Cause in regions of low variance, you can just extrapolate from the neighbors.
Discretization
  * A repeated result in data mining is that collapsing numeric ranges into a small number of bins is a _good idea_
    * Unsupervised discretization:
      * Given _B_ bins with breaks b<sub>1</sub>, b<sub>2</sub>, b<sub>3</sub>,.. containing counts c<sub>1</sub>, c<sub>2</sub>, c<sub>3</sub>...
        * Equal width discretization: (b<sub>i+1</sub> - b<sub>i</sub>) = (b<sub>i</sub> - b<sub>i-i</sub>)
        * Equal frequency  discretization: c<sub>i</sub>= c<sub>j</sub>
      * How many bins?
        * Try _B_=2,4,8,16 or log<sub>2</sub>(number of different values)
    * Supervised discretization:
      * Sort a column of numerics, along with their class score
      * Find the point where the distribution of classes is _most\_different_ left and right of that point
        * Call that b<sub>1</sub>
      * Recurse for all values left and right of the break
        * Recursively generates breaks b<sub>2</sub>, b<sub>3</sub>, etc
          * Note that _B_ is derived, not pre-guessed.
      * Stop recursing when sub-group too small: say, less than sqrt(number of rows)
        * Sub-group has low variance: say, less than 75% of the max log(variance)
  * For more on discretization, see [Dougherty'95](http://code.google.com/p/ourmine/source/browse/trunk/share/pdf/dougherty95supervised.pdf)
Can you better than an initial totally random bias?
  * Any probabilities from the domain?
Should all transitions be re-biased?
  * Perhaps some are not controllable.
How many simulations before re-biasing?
  * Default, try N=100
  * Do we even need to wait N times?
    * Can this be done fully incrementally?
    * FYI, GENIC is incremental.
    * For a simple, but effective, incremental discretizer, see [Gama'06](http://ourmine.googlecode.com/svn/trunk/share/pdf/gama06.pdf)
How to implement the re-biasing?
  * Range selectors
    * let b = f(x in best) / (B/100`*`N)
    * let r = f(x in rest) / (R/100`*`N))
    * log of the odds ratio = log(b/r)
    * tar4.1 b<sup>2</sup>/(b+r)
  * Column selectors
    * Given _N = Best + Rest_ rows
      * P<sub>Best</sub> = Best/N
      * P<sub>Rest</sub> = Rest/N
    * Before:
      * C<sub>i</sub> = how often V<sub>i</sub> appears in all rows
      * p<sub>i,all</sub> = C<sub>i</sub>/N
      * e<sub>i,all</sub> = -p`*`log<sub>2</sub>(p)
      * Before =   ∑ <sub>i</sub> e<sub>i</sub>all
    * After:
      * Divide each column into the values V<sub>1</sub>, V<sub>2</sub>... seen in the classes C<sub>x</sub> = _Best_ or _Rest_.
      * C<sub>i</sub> = how often V<sub>i</sub> appears in the C<sub>x</sub> rows.
      * p<sub>i,best</sub> = C<sub>i</sub>/Best
      * p<sub>i,rest</sub> = C<sub>i</sub>/Rest
      * e<sub>i,x</sub> = -p`*`log<sub>2</sub>(p)
      * After =  ∑<sub>x</sub> (P<sub>x</sub> `*`  (∑ <sub>i</sub> e<sub>i</sub>x))
    * Gain = Before - After
    * Bias the firings towards the transitions with the highest gains.
Divide divided into Rank each column Normalize all the new biases by (bias<sub>i</sub>) /(∑ bias<sub>i</sub>)
  * For more on nomograms, see [Mozina'04](http://ourmine.googlecode.com/svn/trunk/share/pdf/mozina04.pdf)
  * For more on InfoGain, see [Hall'03](http://code.google.com/p/ourmine/wiki/Hh#hall03)
    * Note: InfoGain requires discretization.
  * For more on tar4.1, see [Menzies '05](http://now.unbox.org/all/trunk/doc/05/apes2/talk-v2.pdf)
Support-based pruning during re-biasing??
  * Tar4.1 has a support term, already
    * But do we need more?
  * Perhaps ignore all ranges with b/r < Dull
    * Default: Dull=1
  * Perhaps ignore all ranges with b < Rare`*`(B/100\*N)
    * Default: Rare =0.5
How big should B ("best") be?
  * Default, try 20%
Should we learn how to fix? Or break?
  * Consider another classification scheme: 80% best, 20% rest
  * Then learn how to break the system using:
    * b = f(x in rest) / (B/100`*`N)
    * r = f(x in best) / (R/100`*`N))
When picking:
  * Add some more bias to the bias
  * Don't use rand(), but rand()<sup>w</sup>
    * If w < 1, favors lower biased values less and less.
Is singleton re-biasing enough:
  * Should we work in pairs/triples/etc of data?
  * That is, before re-biasing, do a little search trying out some conjunctions.
  * See tar4.1 or [Keys2](http://agent-ready.googlecode.com/svn/trunk/share/pdf/keys2.pdf)
