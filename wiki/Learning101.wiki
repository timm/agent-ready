#summary learning tricks

The learning mechanism in Actory is a tool that biases machine/transition selection (so it will all be in sub-classes of Stagger).

Biases are learned from watching an oracle score the simulation outputs.
 * Bias,,0,, is fully random (i.e. the current Stagger)
 * Bias,,i,, influences what transitions fire
 * Bias,,i+1,, learned from experience with the running model.

For N simulations:
 * reset
 * run
 * score the output

Generate a table:
 * One column for each transition.
 * One row for each of the N simulations

For each row:
 * Count the number of times each transition fires.
 * Divide those counts by the total number of transitions fired in that row.
 * Add one more column for a _score_ generated by some _oracle_.

Classify the rows
 * Sort the rows 
 * Seperate them out into B% _best_ and (100-B)% _rest_.

Re-bias
 * Increase the bias on transition,,x,, if it appears _more_ frequently in best than _rest_.
 * Normalize all the new biases by (bias,,i,,) /(âˆ‘ bias,,i,,) 
    * So all biases are between zero and one.

Singleton re-normalization
 * Select new biases
 * Sort the transitions in their normalized biased order.
 * Pick _u_ at random (zero to one)
	* Perhaps, bias _u_ to favor the most likely transitions.
 * Starting from transition 2
 * Select transition  _i_ if _u_ is  greater than bucket _u+1_.
{{{
function pick(cdf,n,  bias,u,i) {
    u = bias ? rand()^bias : rand()
    for(i=n-1;i>=1;i--) 
        if (u > cdf[i] ) 
            return i+1
    return n
}
}}}
 * Note: if w < 1, favors lower biased values less and less. 

Repeat for multiple _rounds_ (N runs, re-biasing, repeat).

Visualize the results
 * See Figure 5 of [http://ourmine.googlecode.com/svn/trunk/share/pdf/keys2.pdf Keys2]
 * Median = 50th percentile
 * Spread = 75th percentile
 * Success if:
     * Better medians (better performance)
     * Smaller spreads (more certainty)

= One Million Questions =
Have you made enough decision / domain decisions explict?
  * If important options aren't in the transitions, then this learner won't work.
Have you made too many decision / domain decisions explict?
  * If you code too many transitions, then the learning will fail.
At what level do you learn?
  * All factories/machines/transitions in one big table?
     * Default: yes
  * Manually seperate by factory?
  * Manually seperate by machine?
  * Automatically seperate by clustering?
    * For a fast incremental clusterer, see [http://ourmine.googlecode.com/svn/trunk/share/pdf/gupta04.pdf Gupta'04]'s GENIC algorithm
Is the model ruuning too slow?
  * If the final model takes too long to run..
  * .. need to cluster the log of prior behavior and only try new behaviors in zones of high variability
    * Cause in regions of low variance, you can just extrapolate from the neighbors.
Discretization
  * A repeated result in data mining is that collapsing numeric ranges into a small number of bins is a _good idea_
     * Unsupervised discretizaion:
         * Given _B_ bins with breaks b,,1,,, b,,2,,, b,,3,,,.. countaining counts c,,1,,, c,,2,,, c,,3,,...
            * Equal width discretization: (b,,i+1,, - b,,i,,) = (b,,i,, - b,,i-i,,)  
            * Equal frequency  discretization: c,,i,,= c,,j,,
         * How many bins? 
            * Try B=2,4,8,16 or log,,2,,(number of different values)
     * Supervised discretization:
         * Sort a column of numerics, along with their class score
         * Find the point where the distribution of classes is _most_different_ left and right of that point
             * Call that b,,1,,
         * Recurse for all values left and right of the break
             * Stop when sub-group too small: say, less than sqrt(number of rows)
             * Sub-group has low variance: say, less than 75% of the max log(variance)
  * For more on discretization, see [http://code.google.com/p/ourmine/source/browse/trunk/share/pdf/dougherty95supervised.pdf Dougherty'95]
Can you better than an initial totally random bias?
 * Any probabilities from the domain?
Should all transitions be re-biased?
 * Perhaps some are not controllable.
How many simulations before rebiasing?
 * Default, try N=100 
 * Do we even need to wait N times?
   * Can this be done fully incrementally?
   * FYI, GENIC is incremental.
   * For a simple, but effective, incremental discretizer, see [http://ourmine.googlecode.com/svn/trunk/share/pdf/gama06.pdf Gama'06]
How to implement the re-biasing?
 * Infogain?
 * Some old favorites
   * let b = f(x in best) / (B/100{{{*}}}N)
   * let r = f(x in rest) / (R/100{{{*}}}N))
   * log of the odds ratio = log(b/r)
   * tar4.1 b^2^/(b+r) 
 * For more on nomograms, see [http://ourmine.googlecode.com/svn/trunk/share/pdf/mozina04.pdf Mozina'04]
 * For more on InfoGain, see [http://code.google.com/p/ourmine/wiki/Hh#hall03 Hall'03]
   * Note: InfoGain requires discretization.
 * For more on tar4.1, see [http://now.unbox.org/all/trunk/doc/05/apes2/talk-v2.pdf Menzies '05]
Support-based pruning during re-biasing??
 * Tar4.1 has a support term, already
   * But do we need more?
 * Perhaps ignore all ranges with b/r < Dull
   * Default: Dull=1
 * Perhaps ignore all ranges with b < Rare{{{*}}}(B/100*N)
   * Default: Rare =0.5
How big should B ("best") be? 
 * Default, try 20%
Should we learn how to fix? Or break?
 * Consider another classification scheme: 80% best, 20% rest
 * Then learn how to break the system using: 
   * b = f(x in rest) / (B/100{{{*}}}N)
   * r = f(x in best) / (R/100{{{*}}}N))
When picking:
 * Add some more bias to the bias 
	* Don't use rand(), but rand()^w^
    * If w < 1, favors lower biased values less and less. 
Is singleton rebiasing enough:
 * Should we work in pairs/triples/etc of data?
 * That is, before rebiasing, do a little search trying out some conjunctions.
 * See tar4.1 or [http://ourmine.googlecode.com/svn/trunk/share/pdf/keys2.pdf Keys2]

